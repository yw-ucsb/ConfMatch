# USB basic arguments, may not want to change;
algorithm: confmatch
amp: False
clip: 0.0
use_cat: True
save_dir: /data/y_yin/workspace/usb_cv/cifar100_400
save_name: confmatch_lambda_0.01_uratio_4_mask_align
resume: True
load_path: /data/y_yin/workspace/usb_cv/confmatch/cifar100_400  # /data/y_yin/workspace/usb_cv/confmatch/cifar100_400_5_cp/cifar100_400_5/model_best.pth
overwrite: True
use_tensorboard: False
use_wandb: True
num_log_iter: 256
# Algorithm arguments: FixMatch;
hard_label: True
T: 0.5
p_cutoff: 0.95
ulb_loss_ratio: 1.0
# Algorithm arguments: ConfMatch;
n_repeat_loader_cali: 5
confmatch_alpha: 0.1
confmatch_delta: 0.1
confmatch_gamma: 1.0
conf_loss: True
lambda_conf: 0.01
confmatch_cali_s: False
# Training arguments: Data;
img_size: 32
crop_ratio: 0.875
data_dir: /data/datasets/usb
dataset: cifar100
num_classes: 100
num_labels: 400
# Training arguments: Model;
net: vit_small_patch2_32
net_from_name: False
use_pretrain: True
pretrain_path: https://github.com/microsoft/Semi-supervised-learning/releases/download/v.0.0.0/vit_small_patch2_32_mlp_im_1k_32.pth
# Training arguments: Optimizer;
optim: AdamW
lr: 0.0005
momentum: 0.9
weight_decay: 0.0005
layer_decay: 0.5
num_warmup_iter: 5120
train_sampler: RandomSampler
batch_size: 8
uratio: 4 
# Training arguments: Trainer;
epoch: 100 #200
num_train_iter: 102400 #204800
# Training arguments: GPU and Multi-processing;
num_workers: 4
seed: 0
world_size: 1
rank: 0
multiprocessing_distributed: False
dist_url: tcp://127.0.0.1:10006
dist_backend: nccl
gpu: 1
# Evaluation arguments;
num_eval_iter: 2048
eval_batch_size: 128
ema_m: 0.0
# Finetuning arguments;
ft_optim: SGD
ft_lr: 2e-4 #1e-4
ft_momentum: 0.9
ft_weight_decay: 0.1
ft_layer_decay: 0.5
ft_batch_size: 64
ft_num_warmup_iter: 8192 #4096
ft_epoch: 144
num_ft_iter: 36864


